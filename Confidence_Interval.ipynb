{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have these from your Random Forest model:\n",
        "# y_val (actual labels)\n",
        "# y_val_pred (predicted labels on validation set)\n",
        "\n",
        "# Add placeholder data for demonstration\n",
        "# Replace these with your actual y_val and y_val_pred\n",
        "y_val = np.random.randint(0, 2, 100)  # Example actual labels\n",
        "y_val_pred = np.random.randint(0, 2, 100)  # Example predicted labels\n",
        "\n",
        "\n",
        "# Define bootstrap confidence interval function\n",
        "def bootstrap_ci(y_true, y_pred, metric_func, n_bootstraps=1000, alpha=0.95):\n",
        "    rng = np.random.default_rng(seed=42)\n",
        "    scores = []\n",
        "    n = len(y_true)\n",
        "    for _ in range(n_bootstraps):\n",
        "        idx = rng.integers(0, n, n)\n",
        "        y_true_resample = np.array(y_true)[idx]\n",
        "        y_pred_resample = np.array(y_pred)[idx]\n",
        "        try:\n",
        "            score = metric_func(y_true_resample, y_pred_resample)\n",
        "            scores.append(score)\n",
        "        except Exception:\n",
        "            continue\n",
        "    lower = np.percentile(scores, ((1 - alpha) / 2) * 100)\n",
        "    upper = np.percentile(scores, (1 - (1 - alpha) / 2) * 100)\n",
        "    return np.mean(scores), lower, upper\n",
        "\n",
        "# Compute metrics and confidence intervals\n",
        "acc_mean, acc_low, acc_high = bootstrap_ci(y_val, y_val_pred, accuracy_score)\n",
        "prec_mean, prec_low, prec_high = bootstrap_ci(y_val, y_val_pred, precision_score)\n",
        "rec_mean, rec_low, rec_high = bootstrap_ci(y_val, y_val_pred, recall_score)\n",
        "f1_mean, f1_low, f1_high = bootstrap_ci(y_val, y_val_pred, f1_score)\n",
        "\n",
        "# Display results\n",
        "print(f\"Accuracy: {acc_mean*100:.2f}% ± {((acc_high - acc_low)/2)*100:.2f}\")\n",
        "print(f\"Precision: {prec_mean*100:.2f}% ± {((prec_high - prec_low)/2)*100:.2f}\")\n",
        "print(f\"Recall: {rec_mean*100:.2f}% ± {((rec_high - rec_low)/2)*100:.2f}\")\n",
        "print(f\"F1-Score: {f1_mean*100:.2f}% ± {((f1_high - f1_low)/2)*100:.2f}\")"
      ],
      "metadata": {
        "id": "-dBj-h1Bif3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eeebd9c-2df0-4400-f431-169da34065fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 46.05% ± 10.00\n",
            "Precision: 46.06% ± 13.22\n",
            "Recall: 47.91% ± 13.27\n",
            "F1-Score: 46.74% ± 11.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZzE7ZZczjKFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JflJM6b3jKSN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}