{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-dBj-h1Bif3w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score, precision_recall_curve,\n",
        "    precision_score, recall_score, f1_score\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Load your dataset\n",
        "# Make sure to update the file path to the correct location of your CSV file\n",
        "df = pd.read_csv(\"/content/sample_data/customer_churn_dataset_MASTER.csv\")\n",
        "\n",
        "target = \"Churn\"\n",
        "categorical = [\"Gender\", \"Subscription Type\", \"Contract Length\"]\n",
        "numeric = [c for c in df.columns if c not in categorical + [target, \"CustomerID\"]]\n",
        "\n",
        "# Drop rows with missing values in the 'Churn' column\n",
        "df.dropna(subset=[target], inplace=True)\n",
        "\n",
        "X = df[categorical + numeric]\n",
        "y = df[target].astype(int)\n",
        "\n",
        "# 2) Keep your existing split OR add temporal proxy split if you want to mirror chronology\n",
        "# --- Option A (keep current stratified split) ---\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, stratify=y, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_split_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# --- Option B (temporal proxy split using Tenure + Last Interaction) ---\n",
        "# df_sorted = df.sort_values(by=[\"Tenure\", \"Last Interaction\"])\n",
        "# X_sorted = df_sorted[categorical + numeric]\n",
        "# y_sorted = df_sorted[target].astype(int)\n",
        "# n = len(df_sorted)\n",
        "# train_end, val_end = int(0.70*n), int(0.85*n)\n",
        "# X_train, y_train = X_sorted.iloc[:train_end], y_sorted.iloc[:train_end]\n",
        "# X_val,   y_val   = X_sorted.iloc[train_end:val_end], y_sorted.iloc[train_end:val_end]\n",
        "# X_test,  y_test  = X_sorted.iloc[val_end:], y_sorted.iloc[val_end:]\n",
        "\n",
        "# 3) Preprocessor\n",
        "pre = ColumnTransformer(\n",
        "    transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical)],\n",
        "    remainder=\"passthrough\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8fCoRbri6-R"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression (fast baseline)\n",
        "logreg = LogisticRegression(max_iter=500)\n",
        "logreg_bal = LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
        "\n",
        "# Random Forest (ensemble)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "rf_bal = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
        "\n",
        "pipe_logreg      = Pipeline([(\"pre\", pre), (\"clf\", logreg)])\n",
        "pipe_logreg_bal  = Pipeline([(\"pre\", pre), (\"clf\", logreg_bal)])\n",
        "pipe_rf          = Pipeline([(\"pre\", pre), (\"clf\", rf)])\n",
        "pipe_rf_bal      = Pipeline([(\"pre\", pre), (\"clf\", rf_bal)])\n",
        "\n",
        "pipe_logreg.fit(X_train, y_train)\n",
        "pipe_logreg_bal.fit(X_train, y_train)\n",
        "pipe_rf.fit(X_train, y_train)\n",
        "pipe_rf_bal.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Jwlsmr2ci_2_",
        "outputId": "5c69eac5-fc9b-4731-a9dd-23fa78fce0cd"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pre' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3480196714.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mrf_bal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpipe_logreg\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pre\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"clf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mpipe_logreg_bal\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pre\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"clf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogreg_bal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mpipe_rf\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pre\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"clf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pre' is not defined"
          ]
        }
      ],
      "source": [
        "def pr_metrics(pipe, Xv, yv):\n",
        "    proba = pipe.predict_proba(Xv)[:, 1]\n",
        "    ap = average_precision_score(yv, proba)  # PR-AUC\n",
        "    p, r, t = precision_recall_curve(yv, proba)\n",
        "    return ap, p, r, t, proba\n",
        "\n",
        "# Logistic Regression (fast baseline)\n",
        "logreg = LogisticRegression(max_iter=500)\n",
        "logreg_bal = LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
        "\n",
        "# Random Forest (ensemble)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "rf_bal = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
        "\n",
        "pipe_logreg      = Pipeline([(\"pre\", pre), (\"clf\", logreg)])\n",
        "pipe_logreg_bal  = Pipeline([(\"pre\", pre), (\"clf\", logreg_bal)])\n",
        "pipe_rf          = Pipeline([(\"pre\", pre), (\"clf\", rf)])\n",
        "pipe_rf_bal      = Pipeline([(\"pre\", pre), (\"clf\", rf_bal)])\n",
        "\n",
        "pipe_logreg.fit(X_train, y_train)\n",
        "pipe_logreg_bal.fit(X_train, y_train)\n",
        "pipe_rf.fit(X_train, y_train)\n",
        "pipe_rf_bal.fit(X_train, y_train)\n",
        "\n",
        "models = {\n",
        "    \"LogReg\": pipe_logreg,\n",
        "    \"LogReg_balanced\": pipe_logreg_bal,\n",
        "    \"RandomForest\": pipe_rf,\n",
        "    \"RandomForest_balanced\": pipe_rf_bal,\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, mdl in models.items():\n",
        "    ap, p, r, t, proba = pr_metrics(mdl, X_val, y_val)\n",
        "    results[name] = {\"AP\": ap, \"p\": p, \"r\": r, \"t\": t, \"proba\": proba}\n",
        "\n",
        "def sweep_thresholds(y_true, proba, thresholds):\n",
        "    rows = []\n",
        "    for thr in thresholds:\n",
        "        y_pred = (proba >= thr).astype(int)\n",
        "        rows.append({\n",
        "            \"threshold\": thr,\n",
        "            \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
        "            \"recall\":    recall_score(y_true, y_pred, zero_division=0),\n",
        "            \"f1\":        f1_score(y_true, y_pred, zero_division=0),\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "thr_values = np.round(np.arange(0.30, 0.81, 0.05), 2)\n",
        "rf_sweep     = sweep_thresholds(y_val, results[\"RandomForest\"][\"proba\"], thr_values)\n",
        "rf_bal_sweep = sweep_thresholds(y_val, results[\"RandomForest_balanced\"][\"proba\"], thr_values)\n",
        "\n",
        "best_rf     = rf_sweep.sort_values(\"f1\", ascending=False).iloc[0]\n",
        "best_rf_bal = rf_bal_sweep.sort_values(\"f1\", ascending=False).iloc[0]\n",
        "\n",
        "print(\"PR-AUC (Average Precision):\")\n",
        "for k, v in results.items():\n",
        "    print(f\"  {k}: {v['AP']:.4f}\")\n",
        "\n",
        "print(\"\\nBest RF threshold by F1 (unweighted):\",\n",
        "      dict(best_rf))\n",
        "print(\"Best RF threshold by F1 (balanced):   \",\n",
        "      dict(best_rf_bal))\n",
        "print(\"\\nValidation churn rate:\", y_val.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4F5vCDfjJ4f"
      },
      "outputs": [],
      "source": [
        "# Only enable if churn becomes highly imbalanced (e.g., <20%) in another dataset.\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "# Encode train, then resample:\n",
        "X_train_enc = pre.fit_transform(X_train)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_enc, y_train)\n",
        "# Fit the classifier on resampled data (and use pre.transform for val/test):\n",
        "clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "clf.fit(X_train_res, y_train_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzE7ZZczjKFF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JflJM6b3jKSN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}